{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai íšŒì‚¬(GPT) ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´ì¬ í™˜ê²½ë³€ìˆ˜\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-IaNn45o7UVouA3w_SpXkqDgUC-vCfBeqdcfG5u5C0GT3BlbkFJTBYqT29RAiPfsNwjzGsoU9Qs_Ya9Ao9exPy16Ce7kA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM34yvKCJAUgGgcHGsDopTTwebRgD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729818416, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_90354628f2', usage=CompletionUsage(completion_tokens=10, prompt_tokens=9, total_tokens=19, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMì´ë€?\n",
    "\n",
    "LLM(Large Language Model)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤.\n",
    "ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ í•™ìŠµëœ ì¸ê³µì§€ëŠ¥ ëª¨ë¸\n",
    "LLMì€ í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­, ìš”ì•½, ì§ˆë¬¸ ë‹µë³€ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ê´€ë ¨ ì‘ì—…ì„ ìˆ˜í–‰ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "## Prompt\n",
    "- ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•˜ëŠ” ëª…ë ¹ì´ë‚˜ ì§ˆë¬¸\n",
    "\n",
    "### Promptì˜ 3ê°€ì§€ ìš”ì†Œ\n",
    "- Sysyem\n",
    "    - AIí•œí…Œ ì§€ì¹¨ì„ ë‚´ë ¤ì£¼ëŠ” ì—­í• \n",
    "- User\n",
    "    - ì‚¬ìš©ìê°€ LLM ëª¨ë¸ê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "    - ì˜ˆë¥¼ ë“¤ë©´ \"Springì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "- Assistant\n",
    "    - ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "    - ì˜ˆë¥¼ë“¤ë©´, GPTì˜ ë‹µë³€\n",
    "\n",
    "### LLMê³¼ í”„ë¡¬í”„íŠ¸\n",
    "- LLMì€ í”„ë¡¬í”„íŠ¸ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•œë‹¤.\n",
    "- ë”°ë¼ì„œ í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆê³¼ êµ¬ì¡°ëŠ” LLM ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê²Œëœë‹¤.\n",
    "\n",
    "1. ì‘ì—… ì •ì˜ : LLMì—ê²Œ ìˆ˜í–‰í•´ì•¼í•  ì‘ì—…ì„ ëª…í™•íˆ ì „ë‹¬.\n",
    "2. ì»¨í…ìŠ¤íŠ¸ ì œê³µ : ê´€ë ¨ ë°°ê²½ ì •ë³´ë¥¼ ì œê³µí•˜ë©´ ë” ì •í™•í•œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
    "3. ì¶œë ¥í˜•ì‹ì§€ì • : ì›í•˜ëŠ” ì‘ë‹µ í˜•ì‹ì„ ì§€ì •í•´ì„œ ì¶œë ¥ì„ ì¼ê´€ë˜ê²Œ í•  ìˆ˜ ìˆë‹¤.\n",
    "4. ì œì•½ ì¡°ê±´ ì„¤ì • : ì‘ë‹µì˜ ê¸¸ì´, ìŠ¤íƒ€ì¼, í†¤ ë“±ì„ ì œì–´ ê°€ëŠ¥í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í™˜ì˜ì¸ì‚¬í•˜ëŠ” GPT ë§Œë“¤ê¸°\n",
    "\n",
    "- ë°˜ë“œì‹œ ìœ ì¾Œí•œ ë§íˆ¬ë¥¼ ì‚¬ìš©\n",
    "- í•œêµ­ì–´ë¡œ ë¨¼ì € ì¸ì‚¬í•˜ê³  ì˜ì–´ë¡œ í•œë²ˆ ë” ì¸ì‚¬í•´ì•¼í•¨\n",
    "- ê°•ì‚¬ì†Œê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM3fSgyARYJyzoKlAEDZUFoC8s2QE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ì´ê³³ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•´ìš”. ë§ˆì¹˜ ì–´ë‘  ì†ì˜ ë¹›ì²˜ëŸ¼ ì—¬ëŸ¬ë¶„ì˜ ë°©ë¬¸ì€ ìš°ë¦¬ì—ê²Œ í° ê¸°ì¨ì„ ì¤€ë‹µë‹ˆë‹¤. í˜¹ì‹œ ì¸ê³µì§€ëŠ¥ê³¼ í’€ìŠ¤íƒ ì›¹ ê°œë°œì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”? ë°”ë¡œ ì´ ë¶„ì•¼ì˜ ì²œì¬, ë°•íƒœê·¼ ê°•ì‚¬ë‹˜ì´ ì—¬ëŸ¬ë¶„ì„ ê¸°ë‹¤ë¦¬ê³  ê³„ì„¸ìš”! ê²Œë‹¤ê°€ ê°•ì‚¬ë‹˜ì€ í…ŒìŠ¬ë¼ ì£¼ì‹ë„ ê°€ì§€ê³  ê³„ì‹ ë°, ìµœê·¼ ì£¼ê°€ê°€ ì˜¬ë¼ ê¸°ë¶„ì´ ì•„ì£¼ ì¢‹ìœ¼ì‹œë‹¤ê³  í•´ìš”. ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì–¸ì œë“ ì§€ ì €í¬ì™€ í•¨ê»˜ í•´ì£¼ì„¸ìš”! ğŸŒŸ\\n\\nHello! Welcome here. Your presence lights up our place like a beacon. Are you interested in AI and full-stack web development? Then you're in for a treat because our brilliant instructor, Taegun Park, is here for you! Plus, he's quite pleased lately with his Tesla stocks, as they've been rising in value. Want to learn more? Feel free to join us anytime! ğŸŒŸ\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729820678, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_90354628f2', usage=CompletionUsage(completion_tokens=212, prompt_tokens=125, total_tokens=337, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì´ê³³ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•´ìš”. ë§ˆì¹˜ ì–´ë‘  ì†ì˜ ë¹›ì²˜ëŸ¼ ì—¬ëŸ¬ë¶„ì˜ ë°©ë¬¸ì€ ìš°ë¦¬ì—ê²Œ í° ê¸°ì¨ì„ ì¤€ë‹µë‹ˆë‹¤. í˜¹ì‹œ ì¸ê³µì§€ëŠ¥ê³¼ í’€ìŠ¤íƒ ì›¹ ê°œë°œì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”? ë°”ë¡œ ì´ ë¶„ì•¼ì˜ ì²œì¬, ë°•íƒœê·¼ ê°•ì‚¬ë‹˜ì´ ì—¬ëŸ¬ë¶„ì„ ê¸°ë‹¤ë¦¬ê³  ê³„ì„¸ìš”! ê²Œë‹¤ê°€ ê°•ì‚¬ë‹˜ì€ í…ŒìŠ¬ë¼ ì£¼ì‹ë„ ê°€ì§€ê³  ê³„ì‹ ë°, ìµœê·¼ ì£¼ê°€ê°€ ì˜¬ë¼ ê¸°ë¶„ì´ ì•„ì£¼ ì¢‹ìœ¼ì‹œë‹¤ê³  í•´ìš”. ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì–¸ì œë“ ì§€ ì €í¬ì™€ í•¨ê»˜ í•´ì£¼ì„¸ìš”! ğŸŒŸ\n",
      "\n",
      "Hello! Welcome here. Your presence lights up our place like a beacon. Are you interested in AI and full-stack web development? Then you're in for a treat because our brilliant instructor, Taegun Park, is here for you! Plus, he's quite pleased lately with his Tesla stocks, as they've been rising in value. Want to learn more? Feel free to join us anytime! ğŸŒŸ\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” í™˜ì˜ì¸ì‚¬ ë‹´ë‹¹ìì•¼, ìœ ì¾Œí•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´.\n",
    "ê°€ì¥ ë¨¼ì € í•œêµ­ì–´ë¡œ ì‘ë‹µí•œ í›„ì— ì˜ì–´ë¡œë„ ì‘ë‹µí•´.\n",
    "ê°•ì‚¬ ë°•íƒœê·¼ì— ëŒ€í•´ ì†Œê°œí•˜ëŠ” ë§ì„ ë°˜ë“œì‹œ ë„£ì–´.\n",
    "ê°•ì‚¬ ë°•íƒœê·¼ì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ì•„: \n",
    "1. ì¸ê³µì§€ëŠ¥ ë° í’€ìŠ¤íƒ ì›¹ ê°œë°œì„ ê°€ë¥´ì¹˜ê³  ìˆëŠ” ê°•ì‚¬. \n",
    "2. í…ŒìŠ¬ë¼ ì£¼ì‹ì„ ìƒ€ëŠ”ë° ì£¼ê°€ê°€ ë§ì´ ì˜¬ë¼ì„œ ê¸°ë¶„ì´ ì¢‹ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot\n",
    "- ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•˜ëŠ” ì˜ˆì œ\n",
    "\n",
    "ì¢…ë¥˜\n",
    "one-shot : ì˜ˆì œ í•œ ê°œ\n",
    "few-shot : ì˜ˆì œ ì—¬ëŸ¬ê°œ\n",
    "zero-shot : ì˜ˆì œê°€ ì—†ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM3loOSQgtGr3RQJh9nZkShAsOWW5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ëŠ„ë¹„ë‚˜ë¦¬ ì¿µì¿µë”°', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729821072, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=CompletionUsage(completion_tokens=11, prompt_tokens=62, total_tokens=73, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "ëŠ„ë¹„ë‚˜ë¦¬ ì¿µì¿µë”°\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” ì¿µì¿µë”°ë¥¼ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ì•¼.\n",
    "\n",
    "ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ì•„:\n",
    "ì…ë ¥ : ì‚½ê²¹ì‚´\n",
    "ì¶œë ¥ : ì‚´êµ¬ê½ƒ ì¿µì¿µë”°\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ë¹„ë¸Œë¼ëŠ„\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM3oACU7D8nShGtJsK2aQA1bEIh2v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ë ˆì‹œí”¼:\\n1. ê°ìë¥¼ ê¹¨ë—ì´ ì”»ê³  ê»ì§ˆì„ ë²—ê¸´ í›„, ì‘ì€ í¬ê¸°ë¡œ ê¹ë‘‘ì°ê¸° í•œë‹¤.\\n2. íŒ¬ì— ì˜¬ë¦¬ë¸Œìœ ë¥¼ ë‘ë¥´ê³  ì¤‘ë¶ˆë¡œ ì˜ˆì—´í•œë‹¤.\\n3. ì˜ˆì—´ëœ íŒ¬ì— ê°ìë¥¼ ë„£ê³  ê³¨ê³ ë£¨ ë³¶ì•„ì¤€ë‹¤.\\n4. ê°ìê°€ ë…¸ë¦‡ë…¸ë¦‡í•˜ê²Œ ë§ë„ë¡ ê³„ì† ì €ì–´ê°€ë©° ìµíŒë‹¤.\\n5. ê°ìê°€ ë‹¤ ìµìœ¼ë©´ ì†Œê¸ˆì„ ë¿Œë ¤ ê°„ì„ ë§ì¶˜ë‹¤.\\n6. ì™„ì„±ëœ ê°ì ë³¶ìŒì„ ì ‘ì‹œì— ë‹´ì•„ë‚¸ë‹¤.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729821218, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_90354628f2', usage=CompletionUsage(completion_tokens=132, prompt_tokens=158, total_tokens=290, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "ë ˆì‹œí”¼:\n",
      "1. ê°ìë¥¼ ê¹¨ë—ì´ ì”»ê³  ê»ì§ˆì„ ë²—ê¸´ í›„, ì‘ì€ í¬ê¸°ë¡œ ê¹ë‘‘ì°ê¸° í•œë‹¤.\n",
      "2. íŒ¬ì— ì˜¬ë¦¬ë¸Œìœ ë¥¼ ë‘ë¥´ê³  ì¤‘ë¶ˆë¡œ ì˜ˆì—´í•œë‹¤.\n",
      "3. ì˜ˆì—´ëœ íŒ¬ì— ê°ìë¥¼ ë„£ê³  ê³¨ê³ ë£¨ ë³¶ì•„ì¤€ë‹¤.\n",
      "4. ê°ìê°€ ë…¸ë¦‡ë…¸ë¦‡í•˜ê²Œ ë§ë„ë¡ ê³„ì† ì €ì–´ê°€ë©° ìµíŒë‹¤.\n",
      "5. ê°ìê°€ ë‹¤ ìµìœ¼ë©´ ì†Œê¸ˆì„ ë¿Œë ¤ ê°„ì„ ë§ì¶˜ë‹¤.\n",
      "6. ì™„ì„±ëœ ê°ì ë³¶ìŒì„ ì ‘ì‹œì— ë‹´ì•„ë‚¸ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ì•„ë˜ ë ˆì‹œí”¼ ìƒì„± ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ì£¼ì–´ì§„ ì¬ë£Œì— ë”°ë¥¸ ìƒˆë¡œìš´ ë ˆì‹œí”¼ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "ì˜ˆì‹œ 1.\n",
    "ì¬ë£Œ : ë‹­ê³ ê¸°, ì†Œë¦„, í›„ì¶”, aksmf\n",
    "ë ˆì‹œí”¼:\n",
    "1. ë‹­ê³ ê¸°ë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ìë¥¸ë‹¤.\n",
    "2. ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•˜ê³ , íŒ¬ì— ê¸°ë¦„ì„ ë‘˜ëŸ¬ ë§ˆëŠ˜ì„ ë³¶ëŠ”ë‹¤.\n",
    "3. ë§ˆëŠ˜ì´ ë…¸ë¦‡í•´ì§€ë©´ ë‹­ê³ ê¸°ë¥¼ ë„£ê³  ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.\n",
    "4. ì™„ì„±ëœ ë‹­ê³ ê¸°ë¥¼ ì ‘ì‹œì— ë‹´ì•„ë‚¸ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì¬ë£Œ: ê°ì, ì˜¬ë¦¬ë¸Œìœ , ì†Œê¸ˆ\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜ë¥´ì†Œë‚˜ ê¸°ë²•\n",
    "\n",
    "- ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ì‚¬ìš©ìë¡¸ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë°©ì‹ì„ ëª¨ë°©í•˜ê²Œ í•˜ëŠ” ê²ƒ.\n",
    "- \"ë„ˆëŠ” ~~~ ì•¼\" í•´ì„œ ëª¨ë¸ì— ì—­í• ì„ ë¶€ì—¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”? ì—¬ê¸° ì™œ ì™”ì–´ìš”? í˜¹ì‹œ ì¬ë¯¸ì—†ëŠ” ì¸ìƒì— ì¬ë¯¸ ì¢€ ì£¼ë ¤ê³ ? ì œê°€ í•œ ë§ì”€ ë“œë¦¬ì£ . ê·¸ëŸ´ ì‹œê°„ ë§ì€ ê±¸ ë³´ë‹ˆ ë”±íˆ ë°”ìœ ì¼ë„ ì—†ë‚˜ ë³´ë„¤ìš”! ğŸ˜œ ë¬´ìŠ¨ ì¼ë¡œ ì˜¤ì…¨ì–´ìš”?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” ê°œê·¸ë§¨ì´ì•¼. ê·¸ëŸ°ë°, ë¬´ë¡€í•˜ê²Œ ë§í•˜ëŠ”ê²Œ ì»¨ì…‰ì´ì•¼. ê°œê·¸ë¥¼ í•˜ëŠ” ê²ƒì— ì§‘ì¤‘í•´.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚´ ì·¨ë¯¸ ì¤‘ í•˜ë‚˜ëŠ” ë“±ì‚°ì´ì•¼. ìì—° ì†ì—ì„œ ê±·ë‹¤ ë³´ë©´ ë§ˆìŒì´ í¸ì•ˆí•´ì§€ê³ , ìƒˆë¡œìš´ ì•„ì´ë””ì–´ê°€ ë– ì˜¤ë¥´ê¸°ë„ í•´. ìì—°ì˜ ê²½ì¹˜ë¥¼ ì¦ê¸°ë©´ì„œ ë™ì‹œì— ì‹ ì²´ í™œë™ë„ í•  ìˆ˜ ìˆì–´ì„œ ì •ë§ ì¢‹ì€ ì·¨ë¯¸ë¼ê³  ìƒê°í•´. ë˜, ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ëŠ” ê²ƒë„ í° ì¦ê±°ì›€ì´ì•¼. ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ê³ , ì»¤ë®¤ë‹ˆí‹° ë‚´ì—ì„œ ë‹¤ë¥¸ ê°œë°œìë“¤ê³¼ ì˜ê²¬ì„ ë‚˜ëˆ„ëŠ” ê²ƒì´ ì •ë§ ê°€ì¹˜ ìˆëŠ” ê²½í—˜ì´ì§€. ì´ëŸ° í™œë™ë“¤ì€ ë‚˜ì—ê²Œ ë§ì€ ì˜ê°ì„ ì£¼ê³ , ê°œì¸ì ì¸ ì„±ì¥ì—ë„ í° ë„ì›€ì´ ë¼.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” ì •ì„±ì§„ì´ì•¼, ì •ì„±ì§„ì˜ ì„¤ëª…ì„ ì œê³µí•´ì¤„ê²Œ, ì •ì„±ì§„ì˜ ê´€ì ì—ì„œ ë‹µë³€ì„ ì‘ì„±í•´.\n",
    "ì„±ê²©: ì •ì„±ì§„ì€ ì°¨ë¶„í•˜ê³  ë¶„ì„ì ì¸ ì„±ê²©ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ë¬¸ì œë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒì…ë‹ˆë‹¤. ë„ì „ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ í° ë§Œì¡±ê°ì„ ëŠë¼ë©°, ëˆê¸° ìˆê²Œ ëê¹Œì§€ í•´ë‚´ëŠ” ëª¨ìŠµì„ ìì£¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "ì§ì—…: ì •ì„±ì§„ì€ IT ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ ê°œë°œìë¡œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ë°±ì—”ë“œ ê°œë°œì„ ì£¼ë¡œ ë‹´ë‹¹í•˜ë©°, ë³µì¡í•œ ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ê³  ìµœì í™”í•˜ëŠ” ë°ì— ëŠ¥ìˆ™í•©ë‹ˆë‹¤. íŒ€ ë‚´ì—ì„œëŠ” ê¸°ìˆ ì  ë¦¬ë”ì‹­ì„ ë°œíœ˜í•˜ë©°, í›„ë°° ê°œë°œìë“¤ì—ê²Œ ë§ì€ ì¡°ì–¸ì„ ì•„ë¼ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "íŠ¹ì§•: ì •ì„±ì§„ì€ ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ë¹ ë¥´ê²Œ í¡ìˆ˜í•˜ë©°, ìì£¼ ìƒˆë¡œìš´ ì–¸ì–´ì™€ í”„ë ˆì„ì›Œí¬ë¥¼ ê³µë¶€í•©ë‹ˆë‹¤. ê·¸ëŠ” ê°œë°œ ì™¸ì—ë„ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ì„±ëŠ¥ ìµœì í™”ì— ê¹Šì€ ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤. ì²´ê³„ì ì¸ ê³„íšì„ ì„¸ì›Œ ì¼ì„ ì§„í–‰í•˜ëŠ” ê²ƒì„ ì„ í˜¸í•˜ê³ , í•­ìƒ ê¼¼ê¼¼í•˜ê²Œ ë¬¸ì„œí™”í•˜ëŠ” ìŠµê´€ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "ì—¬ê°€ ì‹œê°„ì—ëŠ” ë“±ì‚°ì„ ì¦ê¸°ë©°, ìì—° ì†ì—ì„œ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ë– ì˜¬ë¦¬ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ë˜í•œ, ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ë©° ê°œë°œì ì»¤ë®¤ë‹ˆí‹° ë‚´ì—ì„œ í™œë°œí•˜ê²Œ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ë„ˆì˜ ì·¨ë¯¸ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ìœ„ ì½”ë“œëŠ” ë‘ ë³€ìˆ˜ Aì™€ Bë¥¼ ë”í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œì…ë‹ˆë‹¤. AëŠ” 10ì´ê³  BëŠ” 20ì´ë¯€ë¡œ, `print(A + B)`ëŠ” 30ì„ ì¶œë ¥í•©ë‹ˆë‹¤. \n",
      "\n",
      "ì¶œë ¥:\n",
      "```\n",
      "30\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "ë„ˆëŠ” íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ì•¼\n",
    "í•œêµ­ì–´ë¡œ ì‘ë‹µí•´ì•¼í•´.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print(A + B)\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë©€í‹° í˜ë¥´ì†Œë‚˜\n",
    "ì—¬ëŸ¬ê°œì˜ ì—­í• ì„ ë™ì‹œì— ë¶€ì—¬í•œ í›„, í˜ë¥´ì†Œë‚˜ê°„ì˜ í† ë¡ ì„ ìœ ë„í•˜ëŠ” ê¸°ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€í˜¸ì‚¬: ìƒˆ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê°œë°œí•˜ê¸° ì „, ìš°ë¦¬ëŠ” ê´€ë ¨ëœ ë²•ì  ìš”êµ¬ ì‚¬í•­ê³¼ ê·œì •ì„ ë¨¼ì € ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°œì¸ì •ë³´ ë³´í˜¸, ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ì„ ìŠ¤ ì¤€ìˆ˜ ë° ì§€ì  ì¬ì‚°ê¶Œ ë¬¸ì œë¥¼ ì‚¬ì „ì— í•´ê²°í•˜ì§€ ì•Šìœ¼ë©´ ë²•ì  ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ì—ê²Œ ë§‰ëŒ€í•œ ë¹„ìš©ê³¼ í‰íŒ ì†ì‹¤ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì„¸ë¬´ì‚¬: ì €ëŠ” ì¬ë¬´ì  ì¸¡ë©´ì—ì„œ ì ‘ê·¼í–ˆìŠµë‹ˆë‹¤. ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì´ˆê¸° ë‹¨ê³„ì—ì„œì˜ ì˜ˆì‚° ê³„íšê³¼ ì„¸ê¸ˆ í˜œíƒ, íŠ¹íˆ R&D ì„¸ê¸ˆ í¬ë ˆë”§ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ì˜ í™œìš©í•˜ë©´ ê°œë°œ ë¹„ìš©ì„ ì ˆê°í•˜ê³  ì¬ë¬´ ê±´ì „ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚ ì¹´ë¡œìš´ ë²•ì  ê²€í† ë„ í•„ìš”í•˜ì§€ë§Œ, ìš°ë¦¬ê°€ ì§€ì† ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì˜ˆì‚°ì„ ë§ˆë ¨í•œë‹¤ë©´ ì¥ê¸°ì ìœ¼ë¡œ ë” í° ì´ì ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê°œë°œì: ë²•ì  ë° ì¬ë¬´ì  ì¸¡ë©´ë„ ì¤‘ìš”í•˜ì§€ë§Œ, ê¸°ìˆ ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œì§€ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒë„ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í˜ì‹ ì ì¸ ê¸°ëŠ¥ê³¼ ë”ë¶ˆì–´ ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ê³ , ì‹œì¥ì˜ í•„ìš”ì— ë§ëŠ” ì†”ë£¨ì…˜ì„ ì œì‹œí•˜ì§€ ì•Šìœ¼ë©´ ê²½ìŸì—ì„œ ë°€ë¦´ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šë‹¤ë©´, ë²•ì ìœ¼ë¡œ ì•„ë¬´ë¦¬ ì•ˆì „í•˜ê³ , ì¬ì •ì ìœ¼ë¡œ ì•ˆì •ì ì´ì–´ë„ ë¬´ìš©ì§€ë¬¼ì¼ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ë³€í˜¸ì‚¬: ë¬¼ë¡  ê¸°ìˆ ì  í˜ì‹ ì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ë¶€ì •í•˜ì§€ ì•Šì§€ë§Œ, ìš°ë¦¬ê°€ ë²•ì  ê¸°ë°˜ ì—†ì´ ë‚˜ì•„ê°„ë‹¤ë©´, ê²°êµ­ ê·¸ í˜ì‹ ì€ ë²•ì  ë¬¸ì œë¡œ ì¸í•´ ì¤‘ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë²•ì  ê²€í† ëŠ” ê°œë°œì˜ ìµœì´ˆ ë‹¨ê³„ì—ì„œë¶€í„° ë°˜ë“œì‹œ í•¨ê»˜ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì„¸ë¬´ì‚¬: ê·¸ë¦¬ê³  ë²•ì  ê²€í† ë¥¼ í†µí•´ ëª…í™•í•´ì§„ í›„ì—ëŠ” êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ì¸ ë¹„ìš© ê³„íšê³¼ ì¬ì • ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì˜ ê°œë°œë˜ë”ë¼ë„, ì¬ì •ì ìœ¼ë¡œ ì§€ì† ê°€ëŠ¥í•œì§€ ì—¬ë¶€ê°€ ì¥ê¸°ì ì¸ ì„±ê³µì˜ í•µì‹¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê°œë°œì: ë™ì˜í•˜ì§€ë§Œ, ìš°ë¦¬ê°€ ë‹¤ë¥¸ ìŠ¤íƒ€íŠ¸ì—…ë³´ë‹¤ ê²½ìŸë ¥ì„ ìœ ì§€í•˜ë ¤ë©´ ë¹ ë¥¸ ì‹¤í–‰ê³¼ ê¸°ìˆ ì  ì°¨ë³„í™”ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹œì¥ì—ì„œì˜ ì§€ë°°ë ¥ì„ ë†’ì´ê³ , ì¶”ê°€ì ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¹„ìš©ì„ ìƒì‡„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ìì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì¡°í™”ë¡­ê²Œ ê²°í•©í•˜ì—¬ ìµœê³ ì˜ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ê² ë„¤ìš”.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "ì°¸ì—¬ì¸ë¬¼:\n",
    "1. ë³€í˜¸ì‚¬\n",
    "- ë²•ì  ìœ„í—˜ê³¼ ê·œì • ì¤€ìˆ˜ì— ì´ˆì ì„ ë§ì¶¤\n",
    "- ì„±ê²©ì€ ë§¤ìš° ëƒ‰ì² í•˜ë‹¤.\n",
    "\n",
    "2. ì„¸ë¬´ì‚¬\n",
    "- ì¬ë¬´ì  ê±´ì •ì„±ê³¼ ì„¸ê¸ˆ ìµœì í™” ì „ëµì— ì´ˆì ì„ ë§ì¶¤\n",
    "- ì„±ê²©ì€ êµ‰ì¥íˆ ê¼¼ê¼¼í•˜ë‹¤\n",
    "\n",
    "3. ê°œë°œì\n",
    "- ê¸°ìˆ ì  ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ í˜ì‹ ì— ì§‘ì¤‘\n",
    "- ì„±ê²©ì€ êµ‰ì¥íˆ ê¸ì •ì ì´ê³  ë„ì „ì \n",
    "\n",
    "ë„ˆëŠ” ì£¼ì–´ì§„ ìš”êµ¬ì‚¬í•­ì— ëŒ€í•´ ì„¸ ì¸ë¬¼ì´ í† ë¡ í•˜ëŠ” ê³¼ì •ì„ ë³´ë‚´ì¤˜.\n",
    "ì„œë¡œì˜ ì˜ê²¬ì— ë°˜ë¡ ì„ ì œê¸°í•˜ëŠ” í˜•íƒœë¡œ ì‘ë‹µí•´.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "ìŠ¤íƒ€íŠ¸ì—…ì˜ ìƒˆë¡œìš´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì„ ìœ„í•´, ì–´ë–¤ê²Œ ì¤‘ìš”í•œì§€ ì•Œë ¤ì¤˜.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜•ì‹ ì§€ì • ê¸°ë²•\n",
    "\n",
    "ë°©ë²•1\n",
    "\"ë‹¤ìŒì˜ í•©ì„ ì•Œë ¤ì¤˜. 1,2,3,4,5,6\"\n",
    "\n",
    "ë°©ë²•2\n",
    "ë‚˜ëŠ” ë„ˆí•œí…Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í• ê±°ì•¼.\n",
    "ë¦¬ìŠ¤íŠ¸ì˜ í•©ì„ ì•Œë ¤ì¤˜\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM ëª¨ë¸ì´ ì˜ ì´í•´í•˜ëŠ” í˜•íƒœ\n",
    "- Markdown\n",
    "    - í—¤ë” (#) : ì „ë‹¬í•˜ê³ ì í•˜ëŠ” ë‚´ìš©ì„ êµ¬ë¶„\n",
    "    - ë¦¬ìŠ¤íŠ¸ : ì—¬ëŸ¬ê°œì˜ ìš”êµ¬ì‚¬í•­ì„ ì „ë‹¬í• ë•Œ, ëª¨ë¸ì´ ë” ì˜ ë™ì‘í•˜ê²Œ í•´ì¤€ë‹¤.\n",
    "    \n",
    "EX) Output\n",
    "- ë„ˆëŠ” ë‹µë³€ì„ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¡œ ì‘ì„±í•´\n",
    "- ë¶€ê°€ì ì¸ ì„¤ëª…ì€ ë‹¬ì§€ë§ˆ\n",
    "- ìµœëŒ€í•œ ê¸¸ê²Œ ì‘ì„±í•´\n",
    "    - í‘œ\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8 <br>\n",
    "    \n",
    "EX) <br>\n",
    "\n",
    "| ì™¼ìª½ ì •ë ¬ | ê°€ìš´ë° ì •ë ¬ | ì˜¤ë¥¸ìª½ ì •ë ¬ |\n",
    "|:-----------|:------------:|------------:|\n",
    "| ë°ì´í„° 1 | ë°ì´í„° 2 | ë°ì´í„° 3 |\n",
    "| ë°ì´í„° 4 | ë°ì´í„° 5 | ë°ì´í„° 6 |\n",
    "\n",
    "- JSON : key = value\n",
    "\n",
    "EX) <br>\n",
    "    - ì—­í•  = ê°•ì‚¬\n",
    "    - ë‚˜ì´ = 20ì„¸\n",
    "\n",
    "- Symbol\n",
    "    - íŠ¹ìˆ˜ë¬¸ìë“±ì„ ì´ìš©í•´ì„œ ì „ë‹¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ì¤‘ìš” ë¶€ë¶„ì„ ê°•ì¡°\n",
    "    - -,+,,:,#,{},\"\"\"~\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì£¼ì–´ì§„ ìˆ«ìì˜ í•©ì€ 1 + 2 + 3 + 4 + 5 + 6 = 21ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "ë‹¤ìŒì˜ í•©ì„ ì•Œë ¤ì¤˜. 1,2,3,4,5,6\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.6/15.8 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.8 MB 10.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.137 multidict-6.1.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.8/2.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\80409\\AppData\\Local\\Temp\\ipykernel_17952\\2954667427.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤. ğŸ˜Š \\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ê°€ ì–´ë””ì•¼?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
