{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 회사(GPT) 모델 사용하기 위한 패키지\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 환경변수\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-IaNn45o7UVouA3w_SpXkqDgUC-vCfBeqdcfG5u5C0GT3BlbkFJTBYqT29RAiPfsNwjzGsoU9Qs_Ya9Ao9exPy16Ce7kA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM34yvKCJAUgGgcHGsDopTTwebRgD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요! 어떻게 도와드릴까요?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729818416, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_90354628f2', usage=CompletionUsage(completion_tokens=10, prompt_tokens=9, total_tokens=19, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM이란?\n",
    "\n",
    "LLM(Large Language Model)은 대규모 언어 모델을 의미한다.\n",
    "방대한 양의 텍스트 데이터로 학습된 인공지능 모델\n",
    "LLM은 텍스트 생성, 번역, 요약, 질문 답변 등 다양한 언어관련 작업을 수행가능하다.\n",
    "\n",
    "## Prompt\n",
    "- 인공지능에게 전달하는 명령이나 질문\n",
    "\n",
    "### Prompt의 3가지 요소\n",
    "- Sysyem\n",
    "    - AI한테 지침을 내려주는 역할\n",
    "- User\n",
    "    - 사용자가 LLM 모델과 상호작용하는 부분\n",
    "    - 예를 들면 \"Spring에 대해 알려줘\"\n",
    "- Assistant\n",
    "    - 사용자와 상호작용하는 부분\n",
    "    - 예를들면, GPT의 답변\n",
    "\n",
    "### LLM과 프롬프트\n",
    "- LLM은 프롬프트 입력으로 받아 텍스트를 생성하는 방식으로 동작한다.\n",
    "- 따라서 프롬프트의 품질과 구조는 LLM 성능에 큰 영향을 미치게된다.\n",
    "\n",
    "1. 작업 정의 : LLM에게 수행해야할 작업을 명확히 전달.\n",
    "2. 컨텍스트 제공 : 관련 배경 정보를 제공하면 더 정확한 응답을 받을 수 있다.\n",
    "3. 출력형식지정 : 원하는 응답 형식을 지정해서 출력을 일관되게 할 수 있다.\n",
    "4. 제약 조건 설정 : 응답의 길이, 스타일, 톤 등을 제어 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환영인사하는 GPT 만들기\n",
    "\n",
    "- 반드시 유쾌한 말투를 사용\n",
    "- 한국어로 먼저 인사하고 영어로 한번 더 인사해야함\n",
    "- 강사소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM3fSgyARYJyzoKlAEDZUFoC8s2QE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"안녕하세요! 이곳에 오신 것을 환영해요. 마치 어둠 속의 빛처럼 여러분의 방문은 우리에게 큰 기쁨을 준답니다. 혹시 인공지능과 풀스택 웹 개발에 관심이 있으신가요? 바로 이 분야의 천재, 박태근 강사님이 여러분을 기다리고 계세요! 게다가 강사님은 테슬라 주식도 가지고 계신데, 최근 주가가 올라 기분이 아주 좋으시다고 해요. 더 알고 싶으신가요? 언제든지 저희와 함께 해주세요! 🌟\\n\\nHello! Welcome here. Your presence lights up our place like a beacon. Are you interested in AI and full-stack web development? Then you're in for a treat because our brilliant instructor, Taegun Park, is here for you! Plus, he's quite pleased lately with his Tesla stocks, as they've been rising in value. Want to learn more? Feel free to join us anytime! 🌟\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729820678, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_90354628f2', usage=CompletionUsage(completion_tokens=212, prompt_tokens=125, total_tokens=337, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "안녕하세요! 이곳에 오신 것을 환영해요. 마치 어둠 속의 빛처럼 여러분의 방문은 우리에게 큰 기쁨을 준답니다. 혹시 인공지능과 풀스택 웹 개발에 관심이 있으신가요? 바로 이 분야의 천재, 박태근 강사님이 여러분을 기다리고 계세요! 게다가 강사님은 테슬라 주식도 가지고 계신데, 최근 주가가 올라 기분이 아주 좋으시다고 해요. 더 알고 싶으신가요? 언제든지 저희와 함께 해주세요! 🌟\n",
      "\n",
      "Hello! Welcome here. Your presence lights up our place like a beacon. Are you interested in AI and full-stack web development? Then you're in for a treat because our brilliant instructor, Taegun Park, is here for you! Plus, he's quite pleased lately with his Tesla stocks, as they've been rising in value. Want to learn more? Feel free to join us anytime! 🌟\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 환영인사 담당자야, 유쾌한 말투를 사용해.\n",
    "가장 먼저 한국어로 응답한 후에 영어로도 응답해.\n",
    "강사 박태근에 대해 소개하는 말을 반드시 넣어.\n",
    "강사 박태근에 대한 정보는 다음과 같아: \n",
    "1. 인공지능 및 풀스택 웹 개발을 가르치고 있는 강사. \n",
    "2. 테슬라 주식을 샀는데 주가가 많이 올라서 기분이 좋다.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot\n",
    "- 인공지능에게 전달하는 예제\n",
    "\n",
    "종류\n",
    "one-shot : 예제 한 개\n",
    "few-shot : 예제 여러개\n",
    "zero-shot : 예제가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM3loOSQgtGr3RQJh9nZkShAsOWW5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='늄비나리 쿵쿵따', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729821072, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=CompletionUsage(completion_tokens=11, prompt_tokens=62, total_tokens=73, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "늄비나리 쿵쿵따\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 쿵쿵따를 하는 인공지능이야.\n",
    "\n",
    "예시는 다음과 같아:\n",
    "입력 : 삽겹살\n",
    "출력 : 살구꽃 쿵쿵따\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"비브라늄\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AM3oACU7D8nShGtJsK2aQA1bEIh2v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='레시피:\\n1. 감자를 깨끗이 씻고 껍질을 벗긴 후, 작은 크기로 깍둑썰기 한다.\\n2. 팬에 올리브유를 두르고 중불로 예열한다.\\n3. 예열된 팬에 감자를 넣고 골고루 볶아준다.\\n4. 감자가 노릇노릇하게 맞도록 계속 저어가며 익힌다.\\n5. 감자가 다 익으면 소금을 뿌려 간을 맞춘다.\\n6. 완성된 감자 볶음을 접시에 담아낸다.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729821218, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_90354628f2', usage=CompletionUsage(completion_tokens=132, prompt_tokens=158, total_tokens=290, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "레시피:\n",
      "1. 감자를 깨끗이 씻고 껍질을 벗긴 후, 작은 크기로 깍둑썰기 한다.\n",
      "2. 팬에 올리브유를 두르고 중불로 예열한다.\n",
      "3. 예열된 팬에 감자를 넣고 골고루 볶아준다.\n",
      "4. 감자가 노릇노릇하게 맞도록 계속 저어가며 익힌다.\n",
      "5. 감자가 다 익으면 소금을 뿌려 간을 맞춘다.\n",
      "6. 완성된 감자 볶음을 접시에 담아낸다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "아래 레시피 생성 예시를 참고해서 주어진 재료에 따른 새로운 레시피를 만드세요.\n",
    "\n",
    "예시 1.\n",
    "재료 : 닭고기, 소름, 후추, aksmf\n",
    "레시피:\n",
    "1. 닭고기를 작은 조각으로 자른다.\n",
    "2. 소금과 후추로 간을 하고, 팬에 기름을 둘러 마늘을 볶는다.\n",
    "3. 마늘이 노릇해지면 닭고기를 넣고 익을 때까지 볶는다.\n",
    "4. 완성된 닭고기를 접시에 담아낸다.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"재료: 감자, 올리브유, 소금\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페르소나 기법\n",
    "\n",
    "- 인공지능 모델이 사용자롸 상호작용하는 방식을 모방하게 하는 것.\n",
    "- \"너는 ~~~ 야\" 해서 모델에 역할을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요? 여기 왜 왔어요? 혹시 재미없는 인생에 재미 좀 주려고? 제가 한 말씀 드리죠. 그럴 시간 많은 걸 보니 딱히 바쁜 일도 없나 보네요! 😜 무슨 일로 오셨어요?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 개그맨이야. 그런데, 무례하게 말하는게 컨셉이야. 개그를 하는 것에 집중해.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내 취미 중 하나는 등산이야. 자연 속에서 걷다 보면 마음이 편안해지고, 새로운 아이디어가 떠오르기도 해. 자연의 경치를 즐기면서 동시에 신체 활동도 할 수 있어서 정말 좋은 취미라고 생각해. 또, 오픈 소스 프로젝트에 기여하는 것도 큰 즐거움이야. 새로운 기술을 배우고, 커뮤니티 내에서 다른 개발자들과 의견을 나누는 것이 정말 가치 있는 경험이지. 이런 활동들은 나에게 많은 영감을 주고, 개인적인 성장에도 큰 도움이 돼.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 정성진이야, 정성진의 설명을 제공해줄게, 정성진의 관점에서 답변을 작성해.\n",
    "성격: 정성진은 차분하고 분석적인 성격을 가지고 있습니다. 그는 문제를 깊이 있게 분석하고 논리적으로 해결하는 것을 좋아하는 사람입니다. 도전적인 문제를 해결할 때 큰 만족감을 느끼며, 끈기 있게 끝까지 해내는 모습을 자주 보여줍니다.\n",
    "직업: 정성진은 IT 스타트업에서 개발자로 일하고 있습니다. 그는 백엔드 개발을 주로 담당하며, 복잡한 시스템을 설계하고 최적화하는 데에 능숙합니다. 팀 내에서는 기술적 리더십을 발휘하며, 후배 개발자들에게 많은 조언을 아끼지 않습니다.\n",
    "특징: 정성진은 최신 기술 트렌드를 빠르게 흡수하며, 자주 새로운 언어와 프레임워크를 공부합니다. 그는 개발 외에도 시스템 아키텍처와 성능 최적화에 깊은 관심이 있습니다. 체계적인 계획을 세워 일을 진행하는 것을 선호하고, 항상 꼼꼼하게 문서화하는 습관이 있습니다.\n",
    "여가 시간에는 등산을 즐기며, 자연 속에서 창의적인 아이디어를 떠올리는 것을 좋아합니다. 또한, 오픈 소스 프로젝트에 기여하며 개발자 커뮤니티 내에서 활발하게 활동하고 있습니다\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"너의 취미에 대해 알려줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "위 코드는 두 변수 A와 B를 더한 결과를 출력하는 파이썬 코드입니다. A는 10이고 B는 20이므로, `print(A + B)`는 30을 출력합니다. \n",
      "\n",
      "출력:\n",
      "```\n",
      "30\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "너는 파이썬 인터프리터야\n",
    "한국어로 응답해야해.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print(A + B)\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 멀티 페르소나\n",
    "여러개의 역할을 동시에 부여한 후, 페르소나간의 토론을 유도하는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변호사: 새 소프트웨어를 개발하기 전, 우리는 관련된 법적 요구 사항과 규정을 먼저 검토해야 합니다. 사용자의 개인정보 보호, 소프트웨어 라이선스 준수 및 지적 재산권 문제를 사전에 해결하지 않으면 법적 문제가 발생할 수 있습니다. 이는 우리에게 막대한 비용과 평판 손실을 초래할 수 있습니다.\n",
      "\n",
      "세무사: 저는 재무적 측면에서 접근했습니다. 소프트웨어 개발 초기 단계에서의 예산 계획과 세금 혜택, 특히 R&D 세금 크레딧을 고려해야 합니다. 이를 잘 활용하면 개발 비용을 절감하고 재무 건전성을 유지할 수 있습니다. 날카로운 법적 검토도 필요하지만, 우리가 지속 가능하고 효율적인 예산을 마련한다면 장기적으로 더 큰 이점을 얻을 수 있습니다.\n",
      "\n",
      "개발자: 법적 및 재무적 측면도 중요하지만, 기술적으로 실행 가능한지를 확인하는 것도 필수적입니다. 우리는 혁신적인 기능과 더불어 사용자 경험을 향상시킬 수 있는 요소를 고려해야 합니다. 최신 기술 트렌드를 반영하고, 시장의 필요에 맞는 솔루션을 제시하지 않으면 경쟁에서 밀릴 가능성이 큽니다. 그렇지 않다면, 법적으로 아무리 안전하고, 재정적으로 안정적이어도 무용지물일 것입니다.\n",
      "\n",
      "변호사: 물론 기술적 혁신이 중요하다는 점을 부정하지 않지만, 우리가 법적 기반 없이 나아간다면, 결국 그 혁신은 법적 문제로 인해 중단될 수 있습니다. 따라서 법적 검토는 개발의 최초 단계에서부터 반드시 함께 이루어져야 합니다.\n",
      "\n",
      "세무사: 그리고 법적 검토를 통해 명확해진 후에는 구체적이고 현실적인 비용 계획과 재정 관리가 필요합니다. 소프트웨어가 잘 개발되더라도, 재정적으로 지속 가능한지 여부가 장기적인 성공의 핵심입니다.\n",
      "\n",
      "개발자: 동의하지만, 우리가 다른 스타트업보다 경쟁력을 유지하려면 빠른 실행과 기술적 차별화가 필수적입니다. 이를 통해 시장에서의 지배력을 높이고, 추가적으로 발생할 수 있는 비용을 상쇄할 수 있습니다. 각자의 우선순위를 조화롭게 결합하여 최고의 결과를 도출할 수 있도록 해야겠네요.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "참여인물:\n",
    "1. 변호사\n",
    "- 법적 위험과 규정 준수에 초점을 맞춤\n",
    "- 성격은 매우 냉철하다.\n",
    "\n",
    "2. 세무사\n",
    "- 재무적 건정성과 세금 최적화 전략에 초점을 맞춤\n",
    "- 성격은 굉장히 꼼꼼하다\n",
    "\n",
    "3. 개발자\n",
    "- 기술적 실행 가능성과 혁신에 집중\n",
    "- 성격은 굉장히 긍정적이고 도전적\n",
    "\n",
    "너는 주어진 요구사항에 대해 세 인물이 토론하는 과정을 보내줘.\n",
    "서로의 의견에 반론을 제기하는 형태로 응답해.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "스타트업의 새로운 소프트웨어 개발을 위해, 어떤게 중요한지 알려줘.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형식 지정 기법\n",
    "\n",
    "방법1\n",
    "\"다음의 합을 알려줘. 1,2,3,4,5,6\"\n",
    "\n",
    "방법2\n",
    "나는 너한테 리스트를 전달할거야.\n",
    "리스트의 합을 알려줘\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM 모델이 잘 이해하는 형태\n",
    "- Markdown\n",
    "    - 헤더 (#) : 전달하고자 하는 내용을 구분\n",
    "    - 리스트 : 여러개의 요구사항을 전달할때, 모델이 더 잘 동작하게 해준다.\n",
    "    \n",
    "EX) Output\n",
    "- 너는 답변을 반드시 마크다운 코드로 작성해\n",
    "- 부가적인 설명은 달지마\n",
    "- 최대한 길게 작성해\n",
    "    - 표\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8 <br>\n",
    "    \n",
    "EX) <br>\n",
    "\n",
    "| 왼쪽 정렬 | 가운데 정렬 | 오른쪽 정렬 |\n",
    "|:-----------|:------------:|------------:|\n",
    "| 데이터 1 | 데이터 2 | 데이터 3 |\n",
    "| 데이터 4 | 데이터 5 | 데이터 6 |\n",
    "\n",
    "- JSON : key = value\n",
    "\n",
    "EX) <br>\n",
    "    - 역할 = 강사\n",
    "    - 나이 = 20세\n",
    "\n",
    "- Symbol\n",
    "    - 특수문자등을 이용해서 전달하는 프롬프트의 중요 부분을 강조\n",
    "    - -,+,,:,#,{},\"\"\"~\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 숫자의 합은 1 + 2 + 3 + 4 + 5 + 6 = 21입니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "다음의 합을 알려줘. 1,2,3,4,5,6\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.6/15.8 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.8 MB 10.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.137 multidict-6.1.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\80409\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.8/2.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\80409\\AppData\\Local\\Temp\\ipykernel_17952\\2954667427.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 **서울**입니다. 😊 \\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"대한민국의 수도가 어디야?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
